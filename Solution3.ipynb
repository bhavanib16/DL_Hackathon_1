{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import pandas as pd\n",
        "import os\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "R9ActCouQEOf"
      },
      "id": "R9ActCouQEOf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip the dataset\n",
        "with zipfile.ZipFile('train.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGnSOuYgk4Aa",
        "outputId": "2d873d7d-4bad-43ae-8da1-269775937af0"
      },
      "id": "FGnSOuYgk4Aa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents extracted to /content/train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "187b841b-b983-447a-9c5d-2c4f5fd76939",
      "metadata": {
        "id": "187b841b-b983-447a-9c5d-2c4f5fd76939"
      },
      "outputs": [],
      "source": [
        "# Load the training data\n",
        "train_df = pd.read_csv('data/train.csv')\n",
        "test_df = pd.read_csv('data/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the training data into training and validation sets\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "21QVS5hqQdX0"
      },
      "id": "21QVS5hqQdX0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define image path\n",
        "image_path = 'data/images/'"
      ],
      "metadata": {
        "id": "SaiwJhK9QiAT"
      },
      "id": "SaiwJhK9QiAT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Dataset class for loading images\n",
        "class VehicleDataset(Dataset):\n",
        "    def __init__(self, dataframe, image_dir, transform=None):\n",
        "        self.dataframe = dataframe\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.image_dir, self.dataframe.iloc[idx, 0])\n",
        "        image = Image.open(img_name).convert('RGB')\n",
        "        label = self.dataframe.iloc[idx, 1] if 'emergency_or_not' in self.dataframe.columns else -1\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "WVGI6iCkQni3"
      },
      "id": "WVGI6iCkQni3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations for the training data with data augmentation\n",
        "#train_transform = transforms.Compose([\n",
        "#    transforms.Resize((224, 224)),\n",
        "#    transforms.RandomHorizontalFlip(),\n",
        "#    transforms.RandomRotation(10),\n",
        "#    transforms.ToTensor(),\n",
        "#])\n",
        "\n",
        "# Define transformations for the testing data\n",
        "#test_transform = transforms.Compose([\n",
        "#    transforms.Resize((224, 224)),\n",
        "#    transforms.ToTensor(),\n",
        "#])"
      ],
      "metadata": {
        "id": "mBarxC3lQoUo"
      },
      "id": "mBarxC3lQoUo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1b4d7a2-21df-418e-8f63-b0a222c13cc8",
      "metadata": {
        "id": "f1b4d7a2-21df-418e-8f63-b0a222c13cc8"
      },
      "outputs": [],
      "source": [
        "# Define transformations for the images\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create datasets and dataloaders\n",
        "train_dataset = VehicleDataset(train_df, image_path, transform=transform)\n",
        "val_dataset = VehicleDataset(val_df, image_path, transform=transform)\n",
        "test_dataset = VehicleDataset(test_df, image_path, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "yvWCcpHAGLqH"
      },
      "id": "yvWCcpHAGLqH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a1fb92d-b4eb-41fa-836c-03361156e7c7",
      "metadata": {
        "id": "8a1fb92d-b4eb-41fa-836c-03361156e7c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a17b2cee-46ca-42cb-f563-7ae566e44230"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 125MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Load pre-trained ResNet18 model and modify the final layer\n",
        "model = models.resnet18(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 2)  # 2 classes: emergency and non-emergency\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8680d3a-ec45-4a82-a6a4-193fee534d90",
      "metadata": {
        "id": "a8680d3a-ec45-4a82-a6a4-193fee534d90"
      },
      "outputs": [],
      "source": [
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed8f9a8a-c214-4acf-8951-eebec64637ec",
      "metadata": {
        "id": "ed8f9a8a-c214-4acf-8951-eebec64637ec"
      },
      "outputs": [],
      "source": [
        "# Training the model with validation\n",
        "num_epochs = 10\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
        "\n",
        "    # Validation step\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    val_accuracy = correct / total\n",
        "    print(f\"Validation Loss: {val_loss/len(val_loader)}, Validation Accuracy: {val_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e41cb2c-f724-490f-8e7f-e705ba7488ed",
      "metadata": {
        "id": "4e41cb2c-f724-490f-8e7f-e705ba7488ed"
      },
      "outputs": [],
      "source": [
        "# Predicting on the test set\n",
        "model.eval()\n",
        "predictions = []\n",
        "with torch.no_grad():\n",
        "    for images, _ in test_loader:\n",
        "        images = images.to(device)\n",
        "        outputs = model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        predictions.extend(preds.cpu().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e46742d9-2e90-4e9a-9ad0-8925811812c7",
      "metadata": {
        "id": "e46742d9-2e90-4e9a-9ad0-8925811812c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d78498d3-1184-4406-c623-20e602cd535e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results have been saved to emergency_vehicle_results.csv\n"
          ]
        }
      ],
      "source": [
        "# Create a submission DataFrame\n",
        "submission_df = pd.DataFrame({'image_names': test_df['image_names'], 'emergency_or_not': predictions})\n",
        "\n",
        "# Save the submission to a CSV file\n",
        "submission_df.to_csv('sample_submission.csv', index=False)\n",
        "\n",
        "print(\"Classification completed and results saved to sample_submission.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rz5E9vu-k2zS"
      },
      "id": "Rz5E9vu-k2zS",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}